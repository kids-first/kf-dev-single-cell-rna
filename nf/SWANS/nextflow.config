params {
    // general parameters
    r_lib_path = "/usr/local/lib/R/site-library/"
    input_dir_list = ""
    input_cr_tar_list = ""
    project = ""
    sample_list = ""
    condition_list = ""
    starting_data = ""
    data_dir = "data/endpoints"
    organism = 'human'
    // doubletFinder parameters
    disable_doubletfinder = false
    mito_cutoff = 15
    ribo_cutoff = 100
    min_feature_threshold = 200
    max_feature_threshold = 3000
    int_components = 30
    dbl_mem = 30 // default mem for doubletFinder jobs
    dbl_threads = 2 // default threads for doubletFinder jobs
    // soupX parameters
    disable_soupx = false
    soupx_start = "" // out, no_clusters, h5
    // anaylze_seurat_object parameters
    aso_processes = 4
    aso_memory = 30000000000 // 30 GB
    run_azimuth = "n"
    azimuth_ref = "" // seurat preset, like adiposeref, bonemarrowref, fetusref, heartref, humancortexref, kidneyref, lungref, pancreasref, pbmcref, tonsilref
    run_transferdata = "n"
    transferdata_ref_file = ""
    transferdata_reduction = ""
    transferdata_annocol = ""
    mito_regression = "n"
    ribo_regression = "n"
    cc_regression = "n"
    cc_method = "standard"
    num_var_features = 3000
    resolution_config = "0.1,0.2,0.3"
    include_tsne = "n"
    scale_data_features = "variable"
    split_layers_by = "Sample"
    normalization_config = "standard,sct"
    integration_config = "cca,rpca,harmony"
    ref_based_integration = "n"
    ref_samples = ""
    regression_file = ""
    // create_images_dge
    storage = "rds"
    conserved_genes = "n"
    visualization = "dot"
    user_gene_file = ""
    // misc
    max_memory = "128 GB"
    max_time = "12h"
    max_cpus = 96
    outdir = "./results"
    // platform flags
    aws_test_instance = false
    sbg_run = false
}

includeConfig 'conf/base.config'
includeConfig 'conf/kids_first.config'
if (params.aws_test_instance){ includeConfig 'conf/aws_instance_test.config' }
if (params.sbg_run){ includeConfig 'conf/sbg.config' }

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_report_${trace_timestamp}.html"
}
timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_timeline_${trace_timestamp}.html"
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
// from: https://github.com/nf-core/sarek/blob/master/nextflow.config
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
